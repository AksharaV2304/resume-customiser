{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7f0bb86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[INFO] Starting resume customization for 30 files...\n",
      "\n",
      "\n",
      "[SUMMARY]\n"
     ]
    }
   ],
   "source": [
    "# import os\n",
    "# import re\n",
    "# import json\n",
    "# import requests\n",
    "# from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "# from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# # ---------------------- CONFIG ----------------------\n",
    "# RAW_FOLDER = r\"C:\\Users\\HN338QQ\\OneDrive - EY\\Documents\\raw and ey curated samples\\Rawresumes\"\n",
    "# JD_FOLDER = r\"C:\\Users\\HN338QQ\\OneDrive - EY\\Documents\\raw and ey curated samples\\JDs\"\n",
    "# MANUAL_FOLDER = r\"C:\\Users\\HN338QQ\\OneDrive - EY\\Documents\\raw and ey curated samples\\manualcustomisedresumes\"\n",
    "# OUTPUT_FOLDER = r\"C:\\Users\\HN338QQ\\OneDrive - EY\\Documents\\raw and ey curated samples\\LLM_Customised_Resumes\"\n",
    "# LLM_URL = \"http://127.0.0.1:1234/v1/chat/completions\"\n",
    "\n",
    "# # Ensure output folder exists\n",
    "# os.makedirs(OUTPUT_FOLDER, exist_ok=True)\n",
    "\n",
    "# # ---------------------- HELPERS ----------------------\n",
    "# def read_file(path):\n",
    "#     try:\n",
    "#         with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "#             return f.read().strip()\n",
    "#     except FileNotFoundError:\n",
    "#         print(f\"[WARN] File not found: {path}\")\n",
    "#         return \"\"\n",
    "#     except Exception as e:\n",
    "#         print(f\"[ERROR] Failed reading {path}: {e}\")\n",
    "#         return \"\"\n",
    "\n",
    "# def scrub_pii(text):\n",
    "#     text = re.sub(r'\\b\\d{10}\\b', '', text)  # phone numbers\n",
    "#     text = re.sub(r'\\S+@\\S+', '', text)     # emails\n",
    "#     text = re.sub(r'http\\S+|www.\\S+', '', text)  # URLs\n",
    "#     return text\n",
    "\n",
    "# def build_prompt(raw_resume, jd_text):\n",
    "#     return f\"\"\"\n",
    "# You are a resume writing expert. Convert the following raw resume to a job-specific resume aligned strictly to the below job description. Remove fluff. Align with structure, skills, and tone used in JD.\n",
    "\n",
    "# [RAW RESUME]\n",
    "# {raw_resume}\n",
    "\n",
    "# [JOB DESCRIPTION]\n",
    "# {jd_text}\n",
    "\n",
    "# [OUTPUT]\n",
    "# \"\"\"\n",
    "\n",
    "# def call_mistral_local(prompt):\n",
    "#     headers = {\"Content-Type\": \"application/json\"}\n",
    "#     payload = {\n",
    "#         \"model\": \"mistral-7b-instruct-v0.3-q4_k_m-gguf\",\n",
    "#         \"messages\": [{\"role\": \"user\", \"content\": prompt}],\n",
    "#         \"temperature\": 0.3,\n",
    "#         \"max_tokens\": 1200,\n",
    "#         \"stream\": False\n",
    "#     }\n",
    "#     try:\n",
    "#         response = requests.post(LLM_URL, headers=headers, json=payload)\n",
    "#         result = response.json()\n",
    "#         return result['choices'][0]['message']['content'].strip()\n",
    "#     except Exception as e:\n",
    "#         print(f\"[ERROR] LLM call failed: {e}\")\n",
    "#         return \"\"\n",
    "\n",
    "# def compute_match(generated, manual):\n",
    "#     if not generated or not manual:\n",
    "#         return 0.0\n",
    "#     tfidf = TfidfVectorizer().fit_transform([generated, manual])\n",
    "#     sim = cosine_similarity(tfidf[0:1], tfidf[1:2])\n",
    "#     return round(float(sim[0][0]) * 100, 2)\n",
    "\n",
    "# def patch_keywords(output, jd_text):\n",
    "#     jd_keywords = set(re.findall(r'\\b\\w+\\b', jd_text.lower()))\n",
    "#     out_words = set(re.findall(r'\\b\\w+\\b', output.lower()))\n",
    "#     missing = jd_keywords - out_words\n",
    "#     if missing:\n",
    "#         output += \"\\n\\n[Added Keywords for Match:]\\n\" + \", \".join(sorted(list(missing))[:10])\n",
    "#     return output\n",
    "\n",
    "# # ---------------------- PIPELINE ----------------------\n",
    "# def run_pipeline():\n",
    "#     results = []\n",
    "\n",
    "#     print(f\"\\n[INFO] Starting resume customization for {len(os.listdir(RAW_FOLDER))} files...\\n\")\n",
    "#     for file in os.listdir(RAW_FOLDER):\n",
    "#         if not file.endswith(\".txt\"):\n",
    "#             continue\n",
    "\n",
    "#         base_name = os.path.splitext(file)[0]\n",
    "#         raw_path = os.path.join(RAW_FOLDER, file)\n",
    "#         jd_path = os.path.join(JD_FOLDER, base_name + \".txt\")\n",
    "#         manual_path = os.path.join(MANUAL_FOLDER, base_name + \".txt\")\n",
    "#         output_path = os.path.join(OUTPUT_FOLDER, base_name + \"_llm_output.txt\")\n",
    "\n",
    "#         raw_text = scrub_pii(read_file(raw_path))\n",
    "#         jd_text = read_file(jd_path)\n",
    "#         manual_text = read_file(manual_path)\n",
    "\n",
    "#         if not raw_text or not jd_text:\n",
    "#             print(f\"[SKIPPED] Missing raw or JD for: {file}\")\n",
    "#             continue\n",
    "\n",
    "#         prompt = build_prompt(raw_text, jd_text)\n",
    "#         llm_output = call_mistral_local(prompt)\n",
    "#         if not llm_output:\n",
    "#             print(f\"[FAIL] No LLM output for {file}\")\n",
    "#             continue\n",
    "\n",
    "#         llm_output = patch_keywords(llm_output, jd_text)\n",
    "#         match_score = compute_match(llm_output, manual_text)\n",
    "\n",
    "#         try:\n",
    "#             with open(output_path, \"w\", encoding=\"utf-8\") as f:\n",
    "#                 f.write(llm_output + f\"\\n\\n[Cosine Similarity Match %]: {match_score}\")\n",
    "#             print(f\"[DONE] {file} | Match %: {match_score}\")\n",
    "#             results.append((file, match_score))\n",
    "#         except Exception as e:\n",
    "#             print(f\"[ERROR] Could not write output for {file}: {e}\")\n",
    "\n",
    "#     print(\"\\n[SUMMARY]\")\n",
    "#     for name, score in results:\n",
    "#         print(f\"{name}: {score}%\")\n",
    "\n",
    "# # ---------------------- MAIN ----------------------\n",
    "# if __name__ == \"__main__\":\n",
    "#     run_pipeline()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6275d8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[INFO] Completed 0 files.\n",
      "[SUMMARY]\n"
     ]
    }
   ],
   "source": [
    "# import os\n",
    "# import re\n",
    "# import json\n",
    "# import requests\n",
    "# from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "# from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# # ---------------------- CONFIG ----------------------\n",
    "# BASE_PATH = r\"C:\\Users\\HN338QQ\\OneDrive - EY\\Documents\\raw and ey curated samples\"\n",
    "# RAW_FOLDER = os.path.join(BASE_PATH, \"Rawresumes\")\n",
    "# JD_FOLDER = os.path.join(BASE_PATH, \"JDs\")\n",
    "# MANUAL_FOLDER = os.path.join(BASE_PATH, \"manualcustomisedresumes\")\n",
    "# OUTPUT_FOLDER = os.path.join(BASE_PATH, \"LLM_Customised_Resumes\")\n",
    "# SAMPLE_PATH = os.path.join(BASE_PATH, \"EY_sample_format1.txt\")\n",
    "# LLM_URL = \"http://127.0.0.1:1234/v1/chat/completions\"\n",
    "\n",
    "# os.makedirs(OUTPUT_FOLDER, exist_ok=True)\n",
    "\n",
    "# # ---------------------- HELPERS ----------------------\n",
    "# def read_file(path):\n",
    "#     try:\n",
    "#         with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "#             return f.read().strip()\n",
    "#     except:\n",
    "#         return \"\"\n",
    "\n",
    "# def scrub_pii(text):\n",
    "#     text = re.sub(r'\\b\\d{10}\\b', '', text)  # phone numbers\n",
    "#     text = re.sub(r'\\S+@\\S+', '', text)     # emails\n",
    "#     text = re.sub(r'http\\S+|www.\\S+', '', text)  # URLs\n",
    "#     return text\n",
    "\n",
    "# def build_prompt(raw_resume, jd_text, sample_text):\n",
    "#     return f\"\"\"\n",
    "# You are a resume customization expert for EY. Customize the following raw resume strictly to match the job description. Use the tone, structure, phrasing, and layout similar to the EY sample format. Focus on relevance, remove fluff, inject skills from JD.\n",
    "\n",
    "# [RAW RESUME]\n",
    "# {raw_resume}\n",
    "\n",
    "# [JOB DESCRIPTION]\n",
    "# {jd_text}\n",
    "\n",
    "# [EXAMPLE EY FORMAT FOR REFERENCE]\n",
    "# {sample_text}\n",
    "\n",
    "# [OUTPUT]\n",
    "# \"\"\"\n",
    "\n",
    "# def call_mistral_local(prompt):\n",
    "#     headers = {\"Content-Type\": \"application/json\"}\n",
    "#     payload = {\n",
    "#         \"model\": \"mistral-7b-instruct-v0.3-q4_k_m-gguf\",\n",
    "#         \"messages\": [{\"role\": \"user\", \"content\": prompt}],\n",
    "#         \"temperature\": 0.3,\n",
    "#         \"max_tokens\": 1200,\n",
    "#         \"stream\": False\n",
    "#     }\n",
    "#     try:\n",
    "#         response = requests.post(LLM_URL, headers=headers, json=payload)\n",
    "#         result = response.json()\n",
    "#         return result['choices'][0]['message']['content'].strip()\n",
    "#     except Exception as e:\n",
    "#         print(f\"[ERROR] LLM call failed: {e}\")\n",
    "#         return \"\"\n",
    "\n",
    "# def compute_match(generated, manual):\n",
    "#     try:\n",
    "#         tfidf = TfidfVectorizer().fit_transform([generated, manual])\n",
    "#         sim = cosine_similarity(tfidf[0:1], tfidf[1:2])\n",
    "#         return round(float(sim[0][0]) * 100, 2)\n",
    "#     except:\n",
    "#         return 0.0\n",
    "\n",
    "# def patch_keywords(output, jd_text):\n",
    "#     jd_keywords = set(re.findall(r'\\b\\w+\\b', jd_text.lower()))\n",
    "#     out_words = set(re.findall(r'\\b\\w+\\b', output.lower()))\n",
    "#     missing = jd_keywords - out_words\n",
    "#     if missing:\n",
    "#         output += \"\\n\\n[Added Keywords for Match:]\\n\" + \", \".join(list(missing)[:10])\n",
    "#     return output\n",
    "\n",
    "# # ---------------------- PIPELINE ----------------------\n",
    "# def run_pipeline():\n",
    "#     results = []\n",
    "#     sample_text = read_file(SAMPLE_PATH)\n",
    "\n",
    "#     if not sample_text:\n",
    "#         print(\"[ERROR] EY sample format file missing or empty.\")\n",
    "#         return\n",
    "\n",
    "#     files_processed = 0\n",
    "#     for file in os.listdir(RAW_FOLDER):\n",
    "#         if not file.endswith(\".txt\"):\n",
    "#             continue\n",
    "\n",
    "#         base_name = os.path.splitext(file)[0]\n",
    "#         raw_path = os.path.join(RAW_FOLDER, file)\n",
    "#         jd_path = os.path.join(JD_FOLDER, base_name + \".txt\")\n",
    "#         manual_path = os.path.join(MANUAL_FOLDER, base_name + \".txt\")\n",
    "#         output_path = os.path.join(OUTPUT_FOLDER, base_name + \"_llm_output.txt\")\n",
    "\n",
    "#         raw_text = scrub_pii(read_file(raw_path))\n",
    "#         jd_text = read_file(jd_path)\n",
    "#         manual_text = read_file(manual_path)\n",
    "\n",
    "#         if not raw_text or not jd_text:\n",
    "#             print(f\"[SKIPPED] Missing raw or JD for: {file}\")\n",
    "#             continue\n",
    "\n",
    "#         prompt = build_prompt(raw_text, jd_text, sample_text)\n",
    "#         llm_output = call_mistral_local(prompt)\n",
    "\n",
    "#         if not llm_output:\n",
    "#             print(f\"[FAIL] No LLM output for {file}\")\n",
    "#             continue\n",
    "\n",
    "#         llm_output = patch_keywords(llm_output, jd_text)\n",
    "#         match_score = compute_match(llm_output, manual_text)\n",
    "\n",
    "#         with open(output_path, \"w\", encoding=\"utf-8\") as f:\n",
    "#             f.write(llm_output + f\"\\n\\n[Cosine Similarity Match %]: {match_score}\")\n",
    "\n",
    "#         print(f\"[DONE] {file} | Match %: {match_score}\")\n",
    "#         results.append((file, match_score))\n",
    "#         files_processed += 1\n",
    "\n",
    "#     print(f\"\\n[INFO] Completed {files_processed} files.\")\n",
    "#     print(\"[SUMMARY]\")\n",
    "#     for name, score in results:\n",
    "#         print(f\"{name}: {score}%\")\n",
    "\n",
    "# # ---------------------- MAIN ----------------------\n",
    "# if __name__ == \"__main__\":\n",
    "#     run_pipeline()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab28df8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] No job descriptions found.\n"
     ]
    }
   ],
   "source": [
    "# import os\n",
    "# import re\n",
    "# import json\n",
    "# import requests\n",
    "# from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "# from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# # ---------------------- CONFIG ----------------------\n",
    "# RAW_FOLDER = r\"C:\\Users\\HN338QQ\\OneDrive - EY\\Documents\\raw and ey curated samples\\Rawresumes\"\n",
    "# JD_FOLDER = r\"C:\\Users\\HN338QQ\\OneDrive - EY\\Documents\\raw and ey curated samples\\JDs\"\n",
    "# SAMPLE_PATH = r\"C:\\Users\\HN338QQ\\OneDrive - EY\\Documents\\raw and ey curated samples\\EY_sample_format1.txt\"\n",
    "# OUTPUT_FOLDER = r\"C:\\Users\\HN338QQ\\OneDrive - EY\\Documents\\raw and ey curated samples\\LLM_Customised_Resumes\"\n",
    "# LLM_URL = \"http://127.0.0.1:1234/v1/chat/completions\"\n",
    "# os.makedirs(OUTPUT_FOLDER, exist_ok=True)\n",
    "\n",
    "# # ---------------------- HELPERS ----------------------\n",
    "# def read_file(path):\n",
    "#     try:\n",
    "#         with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "#             return f.read().strip()\n",
    "#     except:\n",
    "#         return \"\"\n",
    "\n",
    "# def scrub_pii(text):\n",
    "#     text = re.sub(r'\\b\\d{10}\\b', '', text)\n",
    "#     text = re.sub(r'\\S+@\\S+', '', text)\n",
    "#     text = re.sub(r'http\\S+|www.\\S+', '', text)\n",
    "#     return text\n",
    "\n",
    "# def build_prompt(sample_text, raw_resume, jd_text):\n",
    "#     return f\"\"\"\n",
    "# You are a resume writing expert working for EY. Convert the following raw resume into a customized client-facing resume aligned strictly to the below job description. Follow the tone, format, and bullet structure of the sample.\n",
    "\n",
    "# [SAMPLE EY FORMAT]\n",
    "# {sample_text}\n",
    "\n",
    "# [RAW RESUME]\n",
    "# {raw_resume}\n",
    "\n",
    "# [JOB DESCRIPTION]\n",
    "# {jd_text}\n",
    "\n",
    "# [OUTPUT]\n",
    "# \"\"\"\n",
    "\n",
    "# def call_mistral_local(prompt):\n",
    "#     headers = {\"Content-Type\": \"application/json\"}\n",
    "#     payload = {\n",
    "#         \"model\": \"mistral-7b-instruct-v0.3-q4_k_m-gguf\",\n",
    "#         \"messages\": [{\"role\": \"user\", \"content\": prompt}],\n",
    "#         \"temperature\": 0.4,\n",
    "#         \"max_tokens\": 1800,\n",
    "#         \"stream\": False\n",
    "#     }\n",
    "#     try:\n",
    "#         response = requests.post(LLM_URL, headers=headers, json=payload)\n",
    "#         result = response.json()\n",
    "#         return result['choices'][0]['message']['content'].strip()\n",
    "#     except Exception as e:\n",
    "#         print(f\"[ERROR] LLM call failed: {e}\")\n",
    "#         return \"\"\n",
    "\n",
    "# def compute_match(text1, text2):\n",
    "#     try:\n",
    "#         tfidf = TfidfVectorizer().fit_transform([text1, text2])\n",
    "#         sim = cosine_similarity(tfidf[0:1], tfidf[1:2])\n",
    "#         return round(float(sim[0][0]) * 100, 2)\n",
    "#     except:\n",
    "#         return 0.0\n",
    "\n",
    "# def find_best_matching_jd(resume_text, jd_texts):\n",
    "#     scores = []\n",
    "#     for fname, jd_text in jd_texts:\n",
    "#         try:\n",
    "#             tfidf = TfidfVectorizer().fit_transform([resume_text, jd_text])\n",
    "#             sim = cosine_similarity(tfidf[0:1], tfidf[1:2])[0][0]\n",
    "#             scores.append((sim, fname, jd_text))\n",
    "#         except:\n",
    "#             continue\n",
    "#     if not scores:\n",
    "#         return None, \"\"\n",
    "#     best = max(scores, key=lambda x: x[0])\n",
    "#     return best[1], best[2]\n",
    "\n",
    "# # ---------------------- PIPELINE ----------------------\n",
    "# def run_pipeline():\n",
    "#     sample_text = read_file(SAMPLE_PATH)\n",
    "#     if not sample_text:\n",
    "#         print(\"[ERROR] Sample file missing.\")\n",
    "#         return\n",
    "\n",
    "#     # Read all JDs in memory\n",
    "#     jd_texts = []\n",
    "#     for file in os.listdir(JD_FOLDER):\n",
    "#         if file.endswith(\".txt\"):\n",
    "#             path = os.path.join(JD_FOLDER, file)\n",
    "#             text = read_file(path)\n",
    "#             if text:\n",
    "#                 jd_texts.append((file, text))\n",
    "\n",
    "#     if not jd_texts:\n",
    "#         print(\"[ERROR] No job descriptions found.\")\n",
    "#         return\n",
    "\n",
    "#     results = []\n",
    "#     processed = 0\n",
    "#     print(f\"\\n[INFO] Starting batch customization for {len(os.listdir(RAW_FOLDER))} resumes...\\n\")\n",
    "\n",
    "#     for file in os.listdir(RAW_FOLDER):\n",
    "#         if not file.endswith(\".txt\"):\n",
    "#             continue\n",
    "\n",
    "#         raw_path = os.path.join(RAW_FOLDER, file)\n",
    "#         base_name = os.path.splitext(file)[0]\n",
    "#         output_path = os.path.join(OUTPUT_FOLDER, base_name + \"_llm_customised.txt\")\n",
    "\n",
    "#         raw_text = scrub_pii(read_file(raw_path))\n",
    "#         if not raw_text:\n",
    "#             print(f\"[SKIPPED] Raw resume empty: {file}\")\n",
    "#             continue\n",
    "\n",
    "#         jd_filename, best_jd = find_best_matching_jd(raw_text, jd_texts)\n",
    "#         if not best_jd:\n",
    "#             print(f\"[SKIPPED] No matching JD for: {file}\")\n",
    "#             continue\n",
    "\n",
    "#         prompt = build_prompt(sample_text, raw_text, best_jd)\n",
    "#         llm_output = call_mistral_local(prompt)\n",
    "#         if not llm_output:\n",
    "#             print(f\"[FAIL] LLM returned empty for: {file}\")\n",
    "#             continue\n",
    "\n",
    "#         match_score = compute_match(llm_output, best_jd)\n",
    "\n",
    "#         with open(output_path, \"w\", encoding=\"utf-8\") as f:\n",
    "#             f.write(llm_output + f\"\\n\\n[Cosine Similarity Match to JD]: {match_score}%\")\n",
    "\n",
    "#         print(f\"[DONE] {file} → matched with {jd_filename} | Match: {match_score}%\")\n",
    "#         results.append((file, jd_filename, match_score))\n",
    "#         processed += 1\n",
    "\n",
    "#     print(f\"\\n[INFO] Completed {processed} files.\\n[SUMMARY]\")\n",
    "#     for f, j, s in results:\n",
    "#         print(f\"{f} → {j} = {s}%\")\n",
    "\n",
    "# # ---------------------- MAIN ----------------------\n",
    "# if __name__ == \"__main__\":\n",
    "#     run_pipeline()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da4d3296",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Starting resume customization for batch of resumes...\n",
      "\n",
      "[INFO] Completed 0 resumes.\n"
     ]
    }
   ],
   "source": [
    "# import os\n",
    "# import re\n",
    "# import json\n",
    "# import requests\n",
    "# from docx import Document\n",
    "# from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "# from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# # ---------------------- CONFIG ----------------------\n",
    "# RAW_FOLDER = r\"C:\\Users\\HN338QQ\\OneDrive - EY\\Documents\\raw and ey curated samples\\Rawresumes\"\n",
    "# JD_FOLDER = r\"C:\\Users\\HN338QQ\\OneDrive - EY\\Documents\\raw and ey curated samples\\JDs\"\n",
    "# SAMPLE_PATH = r\"C:\\Users\\HN338QQ\\OneDrive - EY\\Documents\\raw and ey curated samples\\EY_sample_format1.txt\"\n",
    "# OUTPUT_FOLDER = r\"C:\\Users\\HN338QQ\\OneDrive - EY\\Documents\\raw and ey curated samples\\LLM_Customised_Resumes\"\n",
    "# LLM_URL = \"http://127.0.0.1:1234/v1/chat/completions\"\n",
    "\n",
    "# os.makedirs(OUTPUT_FOLDER, exist_ok=True)\n",
    "\n",
    "# # ---------------------- HELPERS ----------------------\n",
    "# def read_file(path):\n",
    "#     with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "#         return f.read().strip()\n",
    "\n",
    "# def read_docx_text(path):\n",
    "#     doc = Document(path)\n",
    "#     return \"\\n\".join([para.text for para in doc.paragraphs if para.text.strip()])\n",
    "\n",
    "# def scrub_pii(text):\n",
    "#     text = re.sub(r'\\b\\d{10}\\b', '', text)  # phone numbers\n",
    "#     text = re.sub(r'\\S+@\\S+', '', text)     # emails\n",
    "#     text = re.sub(r'http\\S+|www.\\S+', '', text)  # URLs\n",
    "#     return text\n",
    "\n",
    "# def build_prompt(resume_text, jd_text, sample_format):\n",
    "#     return f\"\"\"\n",
    "# You are a resume writing expert helping an EY consultant convert a raw resume into a client-facing resume tailored to a specific job description.\n",
    "\n",
    "# Strict Instructions:\n",
    "# - Match exactly the section structure, tone, and bullet formatting from the sample.\n",
    "# - Remove fluff and irrelevant content.\n",
    "# - Use keywords from the JD and sample.\n",
    "# - Final resume must follow EY format strictly.\n",
    "\n",
    "# [RAW RESUME]\n",
    "# {resume_text}\n",
    "\n",
    "# [JOB DESCRIPTION]\n",
    "# {jd_text}\n",
    "\n",
    "# [SAMPLE FORMAT]\n",
    "# {sample_format}\n",
    "\n",
    "# [OUTPUT]\n",
    "# \"\"\"\n",
    "\n",
    "# def call_llm(prompt):\n",
    "#     headers = {\"Content-Type\": \"application/json\"}\n",
    "#     payload = {\n",
    "#         \"model\": \"mistral-7b-instruct-v0.3-q4_k_m-gguf\",\n",
    "#         \"messages\": [{\"role\": \"user\", \"content\": prompt}],\n",
    "#         \"temperature\": 0.3,\n",
    "#         \"max_tokens\": 1500,\n",
    "#         \"stream\": False\n",
    "#     }\n",
    "#     try:\n",
    "#         response = requests.post(LLM_URL, headers=headers, json=payload)\n",
    "#         result = response.json()\n",
    "#         return result['choices'][0]['message']['content'].strip()\n",
    "#     except Exception as e:\n",
    "#         print(f\"[ERROR] LLM call failed: {e}\")\n",
    "#         return \"\"\n",
    "\n",
    "# def compute_similarity(text1, text2):\n",
    "#     tfidf = TfidfVectorizer().fit_transform([text1, text2])\n",
    "#     sim = cosine_similarity(tfidf[0:1], tfidf[1:2])\n",
    "#     return round(float(sim[0][0]) * 100, 2)\n",
    "\n",
    "# # ---------------------- PIPELINE ----------------------\n",
    "# def run_customization_pipeline():\n",
    "#     print(f\"[INFO] Starting resume customization for batch of resumes...\")\n",
    "\n",
    "#     sample_format = read_file(SAMPLE_PATH)\n",
    "#     jd_texts = []\n",
    "\n",
    "#     # Read all job descriptions (txt or docx)\n",
    "#     for file in os.listdir(JD_FOLDER):\n",
    "#         path = os.path.join(JD_FOLDER, file)\n",
    "#         if file.endswith(\".txt\"):\n",
    "#             jd = read_file(path)\n",
    "#         elif file.endswith(\".docx\"):\n",
    "#             jd = read_docx_text(path)\n",
    "#         else:\n",
    "#             continue\n",
    "#         if jd.strip():\n",
    "#             jd_texts.append((file, jd))\n",
    "\n",
    "#     if not jd_texts:\n",
    "#         print(\"[ERROR] No job descriptions found.\")\n",
    "#         return\n",
    "\n",
    "#     processed = 0\n",
    "\n",
    "#     for resume_file in os.listdir(RAW_FOLDER):\n",
    "#         if not resume_file.endswith(\".txt\"):\n",
    "#             continue\n",
    "\n",
    "#         resume_path = os.path.join(RAW_FOLDER, resume_file)\n",
    "#         resume_text = read_file(resume_path)\n",
    "#         resume_text = scrub_pii(resume_text)\n",
    "\n",
    "#         if not resume_text.strip():\n",
    "#             print(f\"[SKIPPED] Empty resume: {resume_file}\")\n",
    "#             continue\n",
    "\n",
    "#         # Find best matching JD\n",
    "#         best_jd_file, best_jd_text, best_score = None, \"\", 0\n",
    "#         for jd_name, jd_text in jd_texts:\n",
    "#             score = compute_similarity(resume_text, jd_text)\n",
    "#             if score > best_score:\n",
    "#                 best_score = score\n",
    "#                 best_jd_file = jd_name\n",
    "#                 best_jd_text = jd_text\n",
    "\n",
    "#         if not best_jd_text.strip():\n",
    "#             print(f\"[SKIPPED] No JD matched: {resume_file}\")\n",
    "#             continue\n",
    "\n",
    "#         prompt = build_prompt(resume_text, best_jd_text, sample_format)\n",
    "#         llm_output = call_llm(prompt)\n",
    "\n",
    "#         if not llm_output.strip():\n",
    "#             print(f\"[ERROR] LLM failed: {resume_file}\")\n",
    "#             continue\n",
    "\n",
    "#         match_score = compute_similarity(llm_output, sample_format)\n",
    "#         output_path = os.path.join(OUTPUT_FOLDER, resume_file.replace(\".txt\", \"_customised.txt\"))\n",
    "\n",
    "#         with open(output_path, \"w\", encoding=\"utf-8\") as f:\n",
    "#             f.write(llm_output)\n",
    "#             f.write(f\"\\n\\n[Matched JD]: {best_jd_file}\\n[Match with EY format]: {match_score}%\")\n",
    "\n",
    "#         print(f\"[DONE] {resume_file} | JD: {best_jd_file} | Match %: {match_score}\")\n",
    "#         processed += 1\n",
    "\n",
    "#     print(f\"\\n[INFO] Completed {processed} resumes.\")\n",
    "\n",
    "# # ---------------------- MAIN ----------------------\n",
    "# if __name__ == \"__main__\":\n",
    "#     run_customization_pipeline()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bd492f55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Starting resume customization for batch of resumes...\n",
      "[DONE] Anuska Das.pdf | Match with Sample: 51.75%\n",
      "[DONE] CV_Aarsh.pdf | Match with Sample: 82.83%\n",
      "[DONE] CV_Arnab Roy_Model_Validation.pdf | Match with Sample: 45.24%\n",
      "[DONE] G N Sindhur_resume_2025.pdf | Match with Sample: 60.44%\n",
      "[DONE] Isha Porwal Resume.pdf | Match with Sample: 80.58%\n",
      "[DONE] KartikMohan.pdf | Match with Sample: 77.63%\n",
      "[DONE] Kshitij_Sahdev_CV (002).pdf | Match with Sample: 76.28%\n",
      "[DONE] Kundan_Kumar.pdf | Match with Sample: 73.53%\n",
      "[DONE] Munna Choudhary.pdf | Match with Sample: 78.97%\n",
      "[DONE] Narendra_Sahu_CreditRisk.pdf | Match with Sample: 52.97%\n",
      "[DONE] Naukri_AbhimanyuSingh[3y_7m].pdf | Match with Sample: 54.71%\n",
      "[DONE] Naukri_AnandKumar[10y_0m].pdf | Match with Sample: 71.89%\n",
      "[DONE] Naukri_DEBSUBHRAGHOSH[7y_0m].pdf | Match with Sample: 52.08%\n",
      "[DONE] Naukri_GirishKhandelwal[11y_0m].docx | Match with Sample: 60.79%\n",
      "[DONE] Naukri_SAHILPATIL[2y_11m].pdf | Match with Sample: 71.93%\n",
      "[DONE] Naukri_SusmitaMisra[3y_9m].pdf | Match with Sample: 66.24%\n",
      "[DONE] Naukri_Vaibhav[3y_6m].pdf | Match with Sample: 75.95%\n",
      "[DONE] Naukri_YashRai[4y_0m].pdf | Match with Sample: 59.16%\n",
      "[DONE] Nidhika-Tomar.pdf | Match with Sample: 37.73%\n",
      "[DONE] Praveen R- Resume.pdf | Match with Sample: 57.35%\n",
      "[DONE] Priyajit Bishayee resume 2025.pdf | Match with Sample: 75.71%\n",
      "[DONE] Rajvi Doshi.pdf | Match with Sample: 81.23%\n",
      "[DONE] Resume - Reema Panday.docx | Match with Sample: 63.39%\n",
      "[DONE] Resume.SautrikGanguly.pdf | Match with Sample: 42.05%\n",
      "[DONE] Resume_Rahul_kushwaha.pdf | Match with Sample: 65.45%\n",
      "[SKIPPED] Empty resume: SAIKIRAN KPMG CV-1-2-2.pdf\n",
      "[DONE] Shashwata_Mondal.pdf | Match with Sample: 47.77%\n",
      "[DONE] Stuti Mehrotra_CV 1.pdf | Match with Sample: 49.48%\n",
      "[DONE] Sulagna Paul Resume (1).pdf | Match with Sample: 66.58%\n",
      "[DONE] Vedanti Khokher.pdf | Match with Sample: 82.75%\n",
      "\n",
      "[SUMMARY]\n",
      "Anuska Das.pdf: 51.75%\n",
      "CV_Aarsh.pdf: 82.83%\n",
      "CV_Arnab Roy_Model_Validation.pdf: 45.24%\n",
      "G N Sindhur_resume_2025.pdf: 60.44%\n",
      "Isha Porwal Resume.pdf: 80.58%\n",
      "KartikMohan.pdf: 77.63%\n",
      "Kshitij_Sahdev_CV (002).pdf: 76.28%\n",
      "Kundan_Kumar.pdf: 73.53%\n",
      "Munna Choudhary.pdf: 78.97%\n",
      "Narendra_Sahu_CreditRisk.pdf: 52.97%\n",
      "Naukri_AbhimanyuSingh[3y_7m].pdf: 54.71%\n",
      "Naukri_AnandKumar[10y_0m].pdf: 71.89%\n",
      "Naukri_DEBSUBHRAGHOSH[7y_0m].pdf: 52.08%\n",
      "Naukri_GirishKhandelwal[11y_0m].docx: 60.79%\n",
      "Naukri_SAHILPATIL[2y_11m].pdf: 71.93%\n",
      "Naukri_SusmitaMisra[3y_9m].pdf: 66.24%\n",
      "Naukri_Vaibhav[3y_6m].pdf: 75.95%\n",
      "Naukri_YashRai[4y_0m].pdf: 59.16%\n",
      "Nidhika-Tomar.pdf: 37.73%\n",
      "Praveen R- Resume.pdf: 57.35%\n",
      "Priyajit Bishayee resume 2025.pdf: 75.71%\n",
      "Rajvi Doshi.pdf: 81.23%\n",
      "Resume - Reema Panday.docx: 63.39%\n",
      "Resume.SautrikGanguly.pdf: 42.05%\n",
      "Resume_Rahul_kushwaha.pdf: 65.45%\n",
      "Shashwata_Mondal.pdf: 47.77%\n",
      "Stuti Mehrotra_CV 1.pdf: 49.48%\n",
      "Sulagna Paul Resume (1).pdf: 66.58%\n",
      "Vedanti Khokher.pdf: 82.75%\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import docx\n",
    "import fitz  # PyMuPDF\n",
    "import requests\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# --------------- CONFIG -----------------\n",
    "RAW_FOLDER = r\"C:\\Users\\HN338QQ\\OneDrive - EY\\Documents\\raw and ey curated samples\\Rawresumes\"\n",
    "JD_FOLDER = r\"C:\\Users\\HN338QQ\\OneDrive - EY\\Documents\\raw and ey curated samples\\JDs\"\n",
    "OUTPUT_FOLDER = r\"C:\\Users\\HN338QQ\\OneDrive - EY\\Documents\\raw and ey curated samples\\LLM_Customised_Resumes\"\n",
    "SAMPLE_TEXT_PATH = r\"C:\\Users\\HN338QQ\\OneDrive - EY\\Documents\\Kartik\\EY_ClientFacing_Resume.txt\"\n",
    "LLM_URL = \"http://127.0.0.1:1234/v1/chat/completions\"\n",
    "os.makedirs(OUTPUT_FOLDER, exist_ok=True)\n",
    "\n",
    "# --------------- HELPERS -----------------\n",
    "def read_txt(path):\n",
    "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "        return f.read().strip()\n",
    "\n",
    "def read_pdf(path):\n",
    "    doc = fitz.open(path)\n",
    "    return \"\\n\".join([page.get_text() for page in doc])\n",
    "\n",
    "def read_docx(path):\n",
    "    doc = docx.Document(path)\n",
    "    return \"\\n\".join([p.text for p in doc.paragraphs if p.text.strip()])\n",
    "\n",
    "def read_any_resume(path):\n",
    "    ext = os.path.splitext(path)[1].lower()\n",
    "    if ext == \".pdf\":\n",
    "        return read_pdf(path)\n",
    "    elif ext == \".docx\":\n",
    "        return read_docx(path)\n",
    "    elif ext == \".txt\":\n",
    "        return read_txt(path)\n",
    "    return \"\"\n",
    "\n",
    "def scrub_pii(text):\n",
    "    text = re.sub(r'\\b\\d{10}\\b', '', text)  # phone\n",
    "    text = re.sub(r'\\S+@\\S+', '', text)     # emails\n",
    "    text = re.sub(r'http\\S+|www.\\S+', '', text)  # URLs\n",
    "    return text\n",
    "\n",
    "def call_llm(prompt):\n",
    "    headers = {\"Content-Type\": \"application/json\"}\n",
    "    payload = {\n",
    "        \"model\": \"mistral\",\n",
    "        \"messages\": [{\"role\": \"user\", \"content\": prompt}],\n",
    "        \"temperature\": 0.4,\n",
    "        \"max_tokens\": 1800,\n",
    "        \"stream\": False\n",
    "    }\n",
    "    try:\n",
    "        res = requests.post(LLM_URL, headers=headers, json=payload)\n",
    "        return res.json()[\"choices\"][0][\"message\"][\"content\"].strip()\n",
    "    except Exception as e:\n",
    "        print(f\"[ERROR] LLM Call Failed: {e}\")\n",
    "        return \"\"\n",
    "\n",
    "def compute_similarity(a, b):\n",
    "    vecs = TfidfVectorizer().fit_transform([a, b])\n",
    "    return round(float(cosine_similarity(vecs[0:1], vecs[1:2])[0][0]) * 100, 2)\n",
    "\n",
    "def match_best_jd(resume_text, jd_texts):\n",
    "    best_match = \"\"\n",
    "    best_score = -1\n",
    "    for name, jd in jd_texts:\n",
    "        sim = compute_similarity(resume_text, jd)\n",
    "        if sim > best_score:\n",
    "            best_score = sim\n",
    "            best_match = (name, jd)\n",
    "    return best_match\n",
    "\n",
    "def build_prompt(resume_text, jd_text, sample_text):\n",
    "    return f\"\"\"\n",
    "You are a resume writing expert.\n",
    "\n",
    "Format this resume to align with the job description and exactly follow the structure and tone of the sample. Be concise and role-aligned.\n",
    "\n",
    "[SAMPLE FORMAT]\n",
    "{sample_text.strip()}\n",
    "\n",
    "[JOB DESCRIPTION]\n",
    "{jd_text.strip()}\n",
    "\n",
    "[RAW RESUME]\n",
    "{resume_text.strip()}\n",
    "\n",
    "[FORMATTED OUTPUT]\n",
    "\"\"\"\n",
    "\n",
    "# --------------- MAIN PIPELINE -----------------\n",
    "def run_customization_pipeline():\n",
    "    print(\"[INFO] Starting resume customization for batch of resumes...\")\n",
    "\n",
    "    sample_text = read_txt(SAMPLE_TEXT_PATH)\n",
    "\n",
    "    jd_texts = []\n",
    "    for file in os.listdir(JD_FOLDER):\n",
    "        path = os.path.join(JD_FOLDER, file)\n",
    "        if path.endswith(\".txt\"):\n",
    "            jd_texts.append((file, read_txt(path)))\n",
    "        elif path.endswith(\".docx\"):\n",
    "            jd_texts.append((file, read_docx(path)))\n",
    "\n",
    "    if not jd_texts:\n",
    "        print(\"[ERROR] No job descriptions found.\")\n",
    "        return\n",
    "\n",
    "    results = []\n",
    "\n",
    "    for resume_file in os.listdir(RAW_FOLDER):\n",
    "        path = os.path.join(RAW_FOLDER, resume_file)\n",
    "        if not path.lower().endswith((\".pdf\", \".docx\", \".txt\")):\n",
    "            continue\n",
    "\n",
    "        resume_text = read_any_resume(path)\n",
    "        resume_text = scrub_pii(resume_text)\n",
    "\n",
    "        if not resume_text.strip():\n",
    "            print(f\"[SKIPPED] Empty resume: {resume_file}\")\n",
    "            continue\n",
    "\n",
    "        best_jd_name, best_jd_text = match_best_jd(resume_text, jd_texts)\n",
    "        if not best_jd_text.strip():\n",
    "            print(f\"[SKIPPED] No matching JD found: {resume_file}\")\n",
    "            continue\n",
    "\n",
    "        prompt = build_prompt(resume_text, best_jd_text, sample_text)\n",
    "        llm_output = call_llm(prompt)\n",
    "\n",
    "        if not llm_output:\n",
    "            print(f\"[ERROR] LLM returned nothing: {resume_file}\")\n",
    "            continue\n",
    "\n",
    "        output_path = os.path.join(OUTPUT_FOLDER, f\"{os.path.splitext(resume_file)[0]}_formatted.txt\")\n",
    "        with open(output_path, \"w\", encoding=\"utf-8\") as f:\n",
    "            f.write(llm_output)\n",
    "\n",
    "        score = compute_similarity(sample_text, llm_output)\n",
    "        print(f\"[DONE] {resume_file} | Match with Sample: {score}%\")\n",
    "        results.append((resume_file, score))\n",
    "\n",
    "    print(\"\\n[SUMMARY]\")\n",
    "    for name, score in results:\n",
    "        print(f\"{name}: {score}%\")\n",
    "\n",
    "# ------------------ TRIGGER ---------------------\n",
    "if __name__ == \"__main__\":\n",
    "    run_customization_pipeline()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
