{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a75f79f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Step 1: Retrieving closest-matching JD from local JD folder for ‚Üí Create a JD for a retail IRB model validation requirement. Mention that SQL is a must.\n",
      "‚úÖ JD Retrieved From: C:\\Users\\HN338QQ\\OneDrive - EY\\Documents\\raw and ey curated samples\\JDs\\JD_11.txt\n",
      "\n",
      "Step 2: Reading uploaded resume ‚Üí C:\\Users\\HN338QQ\\OneDrive - EY\\Documents\\raw and ey curated samples\\Rawresumes\\Kundan_Kumar.pdf\n",
      "\n",
      "Step 3: If resume sparse, enrich from closest historical resume\n",
      "\n",
      "Step 4: Sending both JD + resume to LLM for customization\n",
      "LLM call failed: HTTPConnectionPool(host='localhost', port=1234): Read timed out. (read timeout=180)\n",
      "‚ùå Customization failed.\n"
     ]
    }
   ],
   "source": [
    "# import os\n",
    "# import fitz  # PyMuPDF\n",
    "# import docx\n",
    "# import re\n",
    "# import json\n",
    "# import requests\n",
    "# import time\n",
    "# import spacy\n",
    "# from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "# from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# # ------------------- CONFIG -------------------\n",
    "# ey_template_path = r\"C:\\Users\\HN338QQ\\OneDrive - EY\\Documents\\raw and ey curated samples\\EY_sample_resume_template.txt\"\n",
    "# output_dir = r\"C:\\Users\\HN338QQ\\OneDrive - EY\\Documents\\raw and ey curated samples\\final_customised_resumes\"\n",
    "# jd_folder = r\"C:\\Users\\HN338QQ\\OneDrive - EY\\Documents\\raw and ey curated samples\\JDs\"\n",
    "# resume_folder = r\"C:\\Users\\HN338QQ\\OneDrive - EY\\Documents\\raw and ey curated samples\\Rawresumes\"\n",
    "# os.makedirs(output_dir, exist_ok=True)\n",
    "# nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# # ------------------- LLM CALL -------------------\n",
    "# def call_lmstudio(prompt, model=\"zephyr-7b-beta.Q4_K_M.gguf\", retries=3):\n",
    "#     url = \"http://localhost:1234/v1/chat/completions\"\n",
    "#     headers = {\"Content-Type\": \"application/json\"}\n",
    "#     payload = {\n",
    "#         \"model\": model,\n",
    "#         \"messages\": [{\"role\": \"user\", \"content\": prompt}],\n",
    "#         \"temperature\": 0.7,\n",
    "#         \"stream\": False\n",
    "#     }\n",
    "#     for attempt in range(retries):\n",
    "#         try:\n",
    "#             response = requests.post(url, headers=headers, data=json.dumps(payload), timeout=180)\n",
    "#             return response.json()['choices'][0]['message']['content']\n",
    "#         except Exception as e:\n",
    "#             if attempt == retries - 1:\n",
    "#                 print(\"LLM call failed:\", e)\n",
    "#                 return \"\"\n",
    "#             time.sleep(2)\n",
    "\n",
    "# # ------------------- UTILITIES -------------------\n",
    "# def read_text_file(path):\n",
    "#     with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "#         return f.read()\n",
    "\n",
    "# def read_resume_text(file_path):\n",
    "#     if file_path.endswith(\".pdf\"):\n",
    "#         doc = fitz.open(file_path)\n",
    "#         return \"\\n\".join([page.get_text() for page in doc])\n",
    "#     elif file_path.endswith(\".docx\"):\n",
    "#         doc = docx.Document(file_path)\n",
    "#         return \"\\n\".join([p.text for p in doc.paragraphs if p.text.strip()])\n",
    "#     elif file_path.endswith(\".txt\"):\n",
    "#         return read_text_file(file_path)\n",
    "#     return \"\"\n",
    "\n",
    "# def get_best_match(input_text, folder, top_k=1):\n",
    "#     files = [f for f in os.listdir(folder) if f.lower().endswith((\".txt\", \".pdf\", \".docx\"))]\n",
    "#     contents = []\n",
    "#     paths = []\n",
    "#     for f in files:\n",
    "#         full_path = os.path.join(folder, f)\n",
    "#         try:\n",
    "#             contents.append(read_resume_text(full_path))\n",
    "#             paths.append(full_path)\n",
    "#         except:\n",
    "#             continue\n",
    "#     if not contents:\n",
    "#         return None, \"\"\n",
    "#     tfidf = TfidfVectorizer().fit_transform([input_text] + contents)\n",
    "#     sims = cosine_similarity(tfidf[0:1], tfidf[1:]).flatten()\n",
    "#     best_idx = sims.argmax()\n",
    "#     return paths[best_idx], contents[best_idx]\n",
    "\n",
    "# # ------------------- ACCURACY METRICS -------------------\n",
    "# def compute_tfidf_similarity(jd, resume):\n",
    "#     tfidf = TfidfVectorizer().fit_transform([jd, resume])\n",
    "#     return cosine_similarity(tfidf[0:1], tfidf[1:2])[0][0]\n",
    "\n",
    "# def keyword_coverage(jd, resume):\n",
    "#     jd_keywords = set(token.text.lower() for token in nlp(jd) if token.is_alpha and not token.is_stop)\n",
    "#     resume_words = resume.lower()\n",
    "#     matched = [kw for kw in jd_keywords if kw in resume_words]\n",
    "#     return len(matched) / len(jd_keywords) if jd_keywords else 0, matched\n",
    "\n",
    "# def qualitative_relevance(jd, resume):\n",
    "#     jd_words = set(jd.lower().split())\n",
    "#     resume_words = set(resume.lower().split())\n",
    "#     overlap = jd_words.intersection(resume_words)\n",
    "#     return len(overlap) / len(jd_words) if jd_words else 0\n",
    "\n",
    "# def section_audit(text):\n",
    "#     sections = [\"summary\", \"qualification\", \"experience\", \"technical\", \"skill\"]\n",
    "#     present = [sec for sec in sections if sec in text.lower()]\n",
    "#     return present\n",
    "\n",
    "# # ------------------- MAIN FUNCTION -------------------\n",
    "# def customise_resume(prompt_text, resume_path):\n",
    "#     candidate_name = os.path.splitext(os.path.basename(resume_path))[0]\n",
    "\n",
    "#     print(f\"\\nStep 1: Retrieving closest-matching JD from local JD folder for ‚Üí {prompt_text}\")\n",
    "#     jd_path, enriched_jd = get_best_match(prompt_text, jd_folder)\n",
    "#     if not enriched_jd:\n",
    "#         print(\"‚ùå JD retrieval failed.\")\n",
    "#         return\n",
    "#     print(\"‚úÖ JD Retrieved From:\", jd_path)\n",
    "\n",
    "#     print(f\"\\nStep 2: Reading uploaded resume ‚Üí {resume_path}\")\n",
    "#     resume_text = read_resume_text(resume_path)\n",
    "\n",
    "#     print(\"\\nStep 3: If resume sparse, enrich from closest historical resume\")\n",
    "#     if len(resume_text.strip().split()) < 150:\n",
    "#         _, enriched_resume = get_best_match(prompt_text, resume_folder)\n",
    "#         resume_text += \"\\n\\n[ENRICHED CONTEXT]\\n\" + enriched_resume\n",
    "\n",
    "#     print(\"\\nStep 4: Sending both JD + resume to LLM for customization\")\n",
    "#     custom_prompt = f\"\"\"\n",
    "# You are a resume writer. Given the candidate's resume and the job description, rewrite the following sections to align with the JD. DO NOT invent any fake information.\n",
    "\n",
    "# Resume:\n",
    "# {resume_text}\n",
    "\n",
    "# Job Description:\n",
    "# {enriched_jd}\n",
    "\n",
    "# Provide the output in this format (with labels):\n",
    "# SUMMARY:\n",
    "# ...\n",
    "\n",
    "# QUALIFICATIONS:\n",
    "# ...\n",
    "\n",
    "# EXPERIENCE:\n",
    "# ...\n",
    "\n",
    "# TECHNICAL_SKILLS:\n",
    "# ...\n",
    "# \"\"\"\n",
    "#     result = call_lmstudio(custom_prompt)\n",
    "#     if not result:\n",
    "#         print(\"‚ùå Customization failed.\")\n",
    "#         return\n",
    "\n",
    "#     # Extract sections\n",
    "#     summary = re.search(r\"SUMMARY:(.*?)QUALIFICATIONS:\", result, re.DOTALL | re.IGNORECASE)\n",
    "#     qualifications = re.search(r\"QUALIFICATIONS:(.*?)EXPERIENCE:\", result, re.DOTALL | re.IGNORECASE)\n",
    "#     experience = re.search(r\"EXPERIENCE:(.*?)TECHNICAL_SKILLS:\", result, re.DOTALL | re.IGNORECASE)\n",
    "#     tech_skills = re.search(r\"TECHNICAL_SKILLS:(.*)\", result, re.DOTALL | re.IGNORECASE)\n",
    "\n",
    "#     # Fill EY Template\n",
    "#     with open(ey_template_path, \"r\", encoding=\"utf-8\") as f:\n",
    "#         template = f.read()\n",
    "\n",
    "#     final_resume = template\n",
    "#     final_resume = final_resume.replace(\"[CANDIDATE_NAME]\", candidate_name)\n",
    "#     final_resume = final_resume.replace(\"[ROLE]\", prompt_text)\n",
    "#     final_resume = final_resume.replace(\"[SUMMARY]\", summary.group(1).strip() if summary else \"\")\n",
    "#     final_resume = final_resume.replace(\"[QUALIFICATIONS]\", qualifications.group(1).strip() if qualifications else \"\")\n",
    "#     final_resume = final_resume.replace(\"[EXPERIENCE_PLACEHOLDER]\", experience.group(1).strip() if experience else \"\")\n",
    "#     final_resume = final_resume.replace(\"[TECHNICAL_SKILLS]\", tech_skills.group(1).strip() if tech_skills else \"\")\n",
    "\n",
    "#     # Save\n",
    "#     output_path = os.path.join(output_dir, f\"{candidate_name}_customised_resume_RAG.txt\")\n",
    "#     with open(output_path, \"w\", encoding=\"utf-8\") as f:\n",
    "#         f.write(final_resume)\n",
    "\n",
    "#     print(\"\\n‚úÖ Resume customized and saved to:\", output_path)\n",
    "\n",
    "#     # Accuracy Metrics\n",
    "#     tfidf_score = compute_tfidf_similarity(enriched_jd, final_resume)\n",
    "#     keyword_match_ratio, matched_keywords = keyword_coverage(enriched_jd, final_resume)\n",
    "#     qualitative_score = qualitative_relevance(enriched_jd, final_resume)\n",
    "#     section_flags = section_audit(final_resume)\n",
    "\n",
    "#     print(\"\\nüìä Accuracy Metrics:\")\n",
    "#     print(f\"TF-IDF Similarity:            {tfidf_score:.2f}\")\n",
    "#     print(f\"Keyword Coverage Ratio:       {keyword_match_ratio:.2f}\")\n",
    "#     print(f\"Qualitative Relevance:        {qualitative_score:.2f}\")\n",
    "#     print(f\"Matched Keywords:             {matched_keywords}\")\n",
    "#     print(f\"Section Presence Flags:       {section_flags}\\n\")\n",
    "\n",
    "#     return output_path\n",
    "\n",
    "# # ------------------- RUN EXAMPLE -------------------\n",
    "# prompt = \"Create a JD for a retail IRB model validation requirement. Mention that SQL is a must.\"\n",
    "# resume_path = r\"C:\\Users\\HN338QQ\\OneDrive - EY\\Documents\\raw and ey curated samples\\Rawresumes\\Kundan_Kumar.pdf\"\n",
    "\n",
    "# customise_resume(prompt, resume_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b8151b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import fitz  # PyMuPDF\n",
    "import docx\n",
    "import re\n",
    "import json\n",
    "import requests\n",
    "import time\n",
    "import spacy\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# ---- CONFIGURATION ----\n",
    "ey_template_path = r\"C:\\Users\\HN338QQ\\OneDrive - EY\\Documents\\raw and ey curated samples\\EY_sample_resume_template.txt\"\n",
    "output_dir = r\"C:\\Users\\HN338QQ\\OneDrive - EY\\Documents\\raw and ey curated samples\\final_customised_resumes\"\n",
    "jd_folder = r\"C:\\Users\\HN338QQ\\OneDrive - EY\\Documents\\raw and ey curated samples\\JDs\"\n",
    "historical_resume_folder = r\"C:\\Users\\HN338QQ\\OneDrive - EY\\Documents\\raw and ey curated samples\\Rawresumes\"\n",
    "\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "\n",
    "# ---- READERS ----\n",
    "def read_text_from_pdf(pdf_path):\n",
    "    doc = fitz.open(pdf_path)\n",
    "    return \"\\n\".join([page.get_text() for page in doc])\n",
    "\n",
    "def read_text_from_docx(docx_path):\n",
    "    doc = docx.Document(docx_path)\n",
    "    return \"\\n\".join([p.text for p in doc.paragraphs if p.text.strip()])\n",
    "\n",
    "def read_resume_text(file_path):\n",
    "    if file_path.endswith(\".pdf\"):\n",
    "        return read_text_from_pdf(file_path)\n",
    "    elif file_path.endswith(\".docx\"):\n",
    "        return read_text_from_docx(file_path)\n",
    "    else:\n",
    "        with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "            return f.read()\n",
    "\n",
    "def get_closest_match_from_folder(prompt, folder_path):\n",
    "    max_score = 0\n",
    "    best_file = None\n",
    "    prompt_doc = nlp(prompt.lower())\n",
    "    for filename in os.listdir(folder_path):\n",
    "        file_path = os.path.join(folder_path, filename)\n",
    "        if os.path.isfile(file_path):\n",
    "            try:\n",
    "                text = read_resume_text(file_path)\n",
    "                score = prompt_doc.similarity(nlp(text.lower()))\n",
    "                if score > max_score:\n",
    "                    max_score = score\n",
    "                    best_file = file_path\n",
    "            except Exception:\n",
    "                continue\n",
    "    return best_file\n",
    "\n",
    "\n",
    "# ---- METRICS ----\n",
    "def compute_tfidf_similarity(jd, resume):\n",
    "    tfidf = TfidfVectorizer().fit_transform([jd, resume])\n",
    "    return cosine_similarity(tfidf[0:1], tfidf[1:2])[0][0]\n",
    "\n",
    "def keyword_coverage(jd, resume):\n",
    "    jd_keywords = set(token.text.lower() for token in nlp(jd) if token.is_alpha and not token.is_stop)\n",
    "    resume_words = resume.lower()\n",
    "    matched = [kw for kw in jd_keywords if kw in resume_words]\n",
    "    return len(matched) / len(jd_keywords) if jd_keywords else 0, matched\n",
    "\n",
    "def qualitative_relevance(jd, resume):\n",
    "    jd_words = set(jd.lower().split())\n",
    "    resume_words = set(resume.lower().split())\n",
    "    overlap = jd_words.intersection(resume_words)\n",
    "    return len(overlap) / len(jd_words) if jd_words else 0\n",
    "\n",
    "def section_audit(text):\n",
    "    sections = [\"summary\", \"qualification\", \"experience\", \"technical\", \"skill\"]\n",
    "    present = [sec for sec in sections if sec in text.lower()]\n",
    "    return present\n",
    "\n",
    "\n",
    "# ---- LLM STUDIO CALL ----\n",
    "def call_lmstudio(prompt, model=\"zephyr-7b-beta.Q4_K_M.gguf\", retries=2):\n",
    "    url = \"http://127.0.0.1:1234/v1/chat/completions\"\n",
    "    headers = {\"Content-Type\": \"application/json\"}\n",
    "    payload = {\n",
    "        \"model\": model,\n",
    "        \"messages\": [{\"role\": \"user\", \"content\": prompt}],\n",
    "        \"temperature\": 0.7,\n",
    "        \"stream\": False\n",
    "    }\n",
    "\n",
    "    for attempt in range(retries):\n",
    "        try:\n",
    "            print(f\"Sending prompt with {len(prompt)} characters to LLM...\")\n",
    "            response = requests.post(url, headers=headers, data=json.dumps(payload), timeout=600)\n",
    "            return response.json()['choices'][0]['message']['content']\n",
    "        except Exception as e:\n",
    "            print(f\"LLM call failed: {e}\")\n",
    "            time.sleep(2)\n",
    "    return \"\"\n",
    "\n",
    "\n",
    "# ---- MAIN FUNCTION ----\n",
    "def customise_resume(prompt_text, resume_path):\n",
    "    candidate_name = os.path.splitext(os.path.basename(resume_path))[0]\n",
    "\n",
    "    print(f\"Step 1: Retrieving closest-matching JD from local JD folder for ‚Üí {prompt_text}\")\n",
    "    matched_jd_file = get_closest_match_from_folder(prompt_text, jd_folder)\n",
    "    if not matched_jd_file:\n",
    "        print(\"‚ùå No JD file found in folder.\")\n",
    "        return\n",
    "\n",
    "    with open(matched_jd_file, \"r\", encoding=\"utf-8\") as f:\n",
    "        jd_text = f.read()\n",
    "\n",
    "    print(\"‚úÖ JD Retrieved From:\", matched_jd_file)\n",
    "\n",
    "    print(f\"\\nStep 2: Reading uploaded resume ‚Üí {resume_path}\")\n",
    "    resume_text = read_resume_text(resume_path)\n",
    "\n",
    "    print(\"\\nStep 3: If resume sparse, enrich from closest historical resume\")\n",
    "    hist_resume_file = get_closest_match_from_folder(prompt_text, historical_resume_folder)\n",
    "    hist_resume_text = read_resume_text(hist_resume_file) if hist_resume_file else \"\"\n",
    "\n",
    "    enriched_resume_text = resume_text + \"\\n\\n\" + hist_resume_text\n",
    "\n",
    "    # Optional: truncate if too long\n",
    "    if len(enriched_resume_text) > 18000:\n",
    "        enriched_resume_text = enriched_resume_text[:18000]\n",
    "        print(\"üîÅ Resume text truncated for LLM compatibility.\")\n",
    "\n",
    "    print(\"\\nStep 4: Sending both JD + resume to LLM for customization\")\n",
    "    llm_prompt = f\"\"\"\n",
    "You are a resume writer. Given the candidate's resume and the job description, rewrite the following sections to align the resume with the JD. DO NOT INVENT DETAILS. Use only content present in the resume or similar past resumes.\n",
    "\n",
    "Resume:\n",
    "{enriched_resume_text}\n",
    "\n",
    "Job Description:\n",
    "{jd_text}\n",
    "\n",
    "Output Format:\n",
    "SUMMARY:\n",
    "...\n",
    "\n",
    "QUALIFICATIONS:\n",
    "...\n",
    "\n",
    "EXPERIENCE:\n",
    "...\n",
    "\n",
    "TECHNICAL_SKILLS:\n",
    "...\n",
    "\"\"\"\n",
    "\n",
    "    result = call_lmstudio(llm_prompt)\n",
    "    if not result:\n",
    "        print(\"‚ùå Customization failed.\")\n",
    "        return\n",
    "\n",
    "    print(\"\\n=== Raw Output from LLM ===\\n\", result)\n",
    "\n",
    "    summary = re.search(r\"SUMMARY:(.*?)QUALIFICATIONS:\", result, re.DOTALL | re.IGNORECASE)\n",
    "    qualifications = re.search(r\"QUALIFICATIONS:(.*?)EXPERIENCE:\", result, re.DOTALL | re.IGNORECASE)\n",
    "    experience = re.search(r\"EXPERIENCE:(.*?)TECHNICAL_SKILLS:\", result, re.DOTALL | re.IGNORECASE)\n",
    "    tech_skills = re.search(r\"TECHNICAL_SKILLS:(.*)\", result, re.DOTALL | re.IGNORECASE)\n",
    "\n",
    "    with open(ey_template_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        template = f.read()\n",
    "\n",
    "    final_resume = template\n",
    "    final_resume = final_resume.replace(\"[CANDIDATE_NAME]\", candidate_name)\n",
    "    final_resume = final_resume.replace(\"[ROLE]\", prompt_text)\n",
    "    final_resume = final_resume.replace(\"[SUMMARY]\", summary.group(1).strip() if summary else \"\")\n",
    "    final_resume = final_resume.replace(\"[QUALIFICATIONS]\", qualifications.group(1).strip() if qualifications else \"\")\n",
    "    final_resume = final_resume.replace(\"[EXPERIENCE_PLACEHOLDER]\", experience.group(1).strip() if experience else \"\")\n",
    "    final_resume = final_resume.replace(\"[TECHNICAL_SKILLS]\", tech_skills.group(1).strip() if tech_skills else \"\")\n",
    "\n",
    "    output_path = os.path.join(output_dir, f\"{candidate_name}_customised.txt\")\n",
    "    with open(output_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(final_resume)\n",
    "\n",
    "    print(\"‚úÖ Resume customized and saved to:\", output_path)\n",
    "\n",
    "    tfidf_score = compute_tfidf_similarity(jd_text, final_resume)\n",
    "    keyword_match_ratio, matched_keywords = keyword_coverage(jd_text, final_resume)\n",
    "    qualitative_score = qualitative_relevance(jd_text, final_resume)\n",
    "    section_flags = section_audit(final_resume)\n",
    "\n",
    "    print(\"\\nAccuracy Metrics:\")\n",
    "    print(f\"TF-IDF Similarity:            {tfidf_score:.2f}\")\n",
    "    print(f\"Keyword Coverage Ratio:       {keyword_match_ratio:.2f}\")\n",
    "    print(f\"Qualitative Relevance:        {qualitative_score:.2f}\")\n",
    "    print(f\"Matched Keywords:             {matched_keywords}\")\n",
    "    print(f\"Section Presence Flags:       {section_flags}\\n\")\n",
    "\n",
    "\n",
    "# ---- RUN EXAMPLE ----\n",
    "prompt = \"Create a JD for a retail IRB model validation requirement. Mention that SQL is a must.\"\n",
    "resume_path = r\"C:\\Users\\HN338QQ\\OneDrive - EY\\Documents\\raw and ey curated samples\\Rawresumes\\Kundan_Kumar.pdf\"\n",
    "\n",
    "customise_resume(prompt, resume_path)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
